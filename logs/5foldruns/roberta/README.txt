Model: roberta-base
Labels: 94
K-Fold: 5
Hyperparameters:
  epochs=5
  learning_rate=2e-05
  max_len=256
  train_batch=8
  eval_batch=16
  warmup_ratio=0.06
  weight_decay=0.01
  fp16=False
  threshold=0.5
