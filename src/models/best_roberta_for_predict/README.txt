Model: roberta-base
Labels: 985
K-Fold: None (fixed splits)
Hyperparameters:
  epochs=5
  learning_rate=3e-05
  max_len=384
  train_batch=8
  eval_batch=16
  warmup_ratio=0.06
  weight_decay=0.01
  fp16=False
  threshold=0.5
